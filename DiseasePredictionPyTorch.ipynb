{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1197f261-a1e2-4d50-b081-12e3e5fda186",
   "metadata": {},
   "source": [
    "# Diabetes Prediction with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9bd70e-1d8c-4d8f-9edd-ec48716b47c0",
   "metadata": {},
   "source": [
    "In the previous notebook, I went through the process of cleaning the data from the Behavioral Risk Factor Surveillance System (BRFSS) for 2020 and testing a few classication algorithms to predict the likelihood of having or developing diabetes. The accuracy score was around 73% and we ended with quite a number of False Positives and False Negatives. The purpose of this notebook is to see if I can improve the accuracy by using PyTorch for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0a6b8-02f2-432b-ac5f-154bad0acf33",
   "metadata": {},
   "source": [
    "## 1. Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7802af59-0d3a-46b9-bee1-993145b2f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a20602c8-248a-4f6a-8450-670921b1328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn import metrics\n",
    "import io\n",
    "import time\n",
    "sns.set(style='ticks')\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69202a71-ccd1-4661-86d0-c17b23e1cb7f",
   "metadata": {},
   "source": [
    "## 2. Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1dbe9725-e95a-43d2-a7fb-e04becec1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the CSV saved from pervious notebook\n",
    "final_df = pd.read_csv('final_df.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb890528-b2fc-4563-b7ef-123d6fccf6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Birth_Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>Marital</th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Physical_Health</th>\n",
       "      <th>Health_Coverage</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Drinker</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Medical_Cost</th>\n",
       "      <th>Overweight</th>\n",
       "      <th>Heart_Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes  Age  Race  Birth_Sex  Education  Income  Marital  General_Health  \\\n",
       "0       1.0  5.0   1.0        0.0        6.0     1.0      2.0             2.0   \n",
       "1       1.0  6.0   1.0        1.0        4.0     5.0      4.0             4.0   \n",
       "2       1.0  6.0   1.0        0.0        5.0     4.0      3.0             3.0   \n",
       "3       1.0  6.0   1.0        1.0        6.0     7.0      1.0             2.0   \n",
       "4       1.0  6.0   2.0        0.0        4.0     2.0      3.0             4.0   \n",
       "\n",
       "   Physical_Health  Health_Coverage  Smoker  Drinker  Physical_Activity  \\\n",
       "0              3.0              2.0     1.0      1.0                1.0   \n",
       "1             20.0              1.0     3.0      1.0                1.0   \n",
       "2              5.0              1.0     3.0      1.0                2.0   \n",
       "3              0.0              1.0     3.0      1.0                1.0   \n",
       "4              0.0              1.0     3.0      1.0                2.0   \n",
       "\n",
       "   Medical_Cost  Overweight  Heart_Disease  \n",
       "0           1.0         1.0            2.0  \n",
       "1           2.0         2.0            2.0  \n",
       "2           2.0         2.0            2.0  \n",
       "3           2.0         2.0            2.0  \n",
       "4           2.0         2.0            2.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9268d-8b25-4707-9427-07298fa73eab",
   "metadata": {},
   "source": [
    "## 3. Split Data into Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62aba63a-e6eb-4dd8-a248-d6cb0ef7be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate dataset into labels and features. Label is the diabetes column\n",
    "X = np.array(final_df.drop(['Diabetes'], axis=1))\n",
    "y = np.array(final_df['Diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15208140-43d6-46b4-b450-5900fdf8d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and testing for models\n",
    "#can add random_state=<some value>. This would ensure we get the same sets each time\n",
    "#70% for the train and 30% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7cf301e5-c08b-40f0-a92f-3b150cd95f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to create our tensors tensors\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_train_t = torch.LongTensor(y_train)\n",
    "y_test_t = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c018403-846a-42e3-9ad7-9015b470f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1.,  ..., 2., 1., 2.],\n",
       "        [5., 1., 1.,  ..., 2., 2., 2.],\n",
       "        [5., 2., 0.,  ..., 2., 2., 2.],\n",
       "        ...,\n",
       "        [6., 1., 0.,  ..., 2., 2., 2.],\n",
       "        [4., 1., 0.,  ..., 2., 2., 2.],\n",
       "        [5., 1., 0.,  ..., 2., 1., 2.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking one of the Tensors\n",
    "X_train_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335b926-2868-4443-b415-b2367e157e8c",
   "metadata": {},
   "source": [
    "## 4. Building and Training Artificial Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54c265bb-910a-4855-b45d-6f5fa0e26e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model with PyTorch. DEfine the class\n",
    "#We have 15 features on input=15 and 2 hidden layers (30 inputs each) and out_put = 2\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_features=15, hidden1=64, hidden2=128, out_features=2):\n",
    "        super().__init__()\n",
    "        self.f_connected1 =  nn.Linear(input_features, hidden1)\n",
    "        self.f_connected2 = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.f_connected1(x))\n",
    "        x = F.relu(self.f_connected2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "863f5388-bbad-4a30-a9fd-3c94c48e845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate my model\n",
    "torch.manual_seed(20)\n",
    "model = ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82af66a0-0f5f-4a3f-a09a-15ff7f4d2f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ANN_Model(\n",
       "  (f_connected1): Linear(in_features=15, out_features=64, bias=True)\n",
       "  (f_connected2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the model parameters\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae57b53b-1a12-4edc-a86c-6e7d8a204993",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backward propogation -- Define the loss_function and define the optimizer\n",
    "#model.parameters() will return a generator that's why we used the brackets\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ceec152-2f6b-4a86-bad4-2267bd979a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1 and the loss: 0.7230020761489868\n",
      "Epoch number: 11 and the loss: 0.6019874215126038\n",
      "Epoch number: 21 and the loss: 0.5560014843940735\n",
      "Epoch number: 31 and the loss: 0.5427707433700562\n",
      "Epoch number: 41 and the loss: 0.5352184772491455\n",
      "Epoch number: 51 and the loss: 0.5310775637626648\n",
      "Epoch number: 61 and the loss: 0.5293008089065552\n",
      "Epoch number: 71 and the loss: 0.5286121368408203\n",
      "Epoch number: 81 and the loss: 0.5280584692955017\n",
      "Epoch number: 91 and the loss: 0.5269811749458313\n",
      "Epoch number: 101 and the loss: 0.526321530342102\n",
      "Epoch number: 111 and the loss: 0.5258094668388367\n",
      "Epoch number: 121 and the loss: 0.5249330997467041\n",
      "Epoch number: 131 and the loss: 0.5246785879135132\n",
      "Epoch number: 141 and the loss: 0.5239773392677307\n",
      "Epoch number: 151 and the loss: 0.5236549973487854\n",
      "Epoch number: 161 and the loss: 0.5240423083305359\n",
      "Epoch number: 171 and the loss: 0.5247637629508972\n",
      "Epoch number: 181 and the loss: 0.5226103663444519\n",
      "Epoch number: 191 and the loss: 0.5223694443702698\n",
      "Epoch number: 201 and the loss: 0.5226050019264221\n",
      "Epoch number: 211 and the loss: 0.5217711329460144\n",
      "Epoch number: 221 and the loss: 0.5216511487960815\n",
      "Epoch number: 231 and the loss: 0.5212299823760986\n",
      "Epoch number: 241 and the loss: 0.5212929844856262\n",
      "Epoch number: 251 and the loss: 0.5208307504653931\n",
      "Epoch number: 261 and the loss: 0.5205072164535522\n",
      "Epoch number: 271 and the loss: 0.5202580094337463\n",
      "Epoch number: 281 and the loss: 0.5202421545982361\n",
      "Epoch number: 291 and the loss: 0.5197054743766785\n",
      "Epoch number: 301 and the loss: 0.519633948802948\n",
      "Epoch number: 311 and the loss: 0.5201576352119446\n",
      "Epoch number: 321 and the loss: 0.5211439728736877\n",
      "Epoch number: 331 and the loss: 0.5201646685600281\n",
      "Epoch number: 341 and the loss: 0.5205029845237732\n",
      "Epoch number: 351 and the loss: 0.5198501348495483\n",
      "Epoch number: 361 and the loss: 0.5188208222389221\n",
      "Epoch number: 371 and the loss: 0.5186875462532043\n",
      "Epoch number: 381 and the loss: 0.5179263949394226\n",
      "Epoch number: 391 and the loss: 0.521397054195404\n",
      "Epoch number: 401 and the loss: 0.5178161263465881\n",
      "Epoch number: 411 and the loss: 0.5174850225448608\n",
      "Epoch number: 421 and the loss: 0.5172908902168274\n",
      "Epoch number: 431 and the loss: 0.5170987248420715\n",
      "Epoch number: 441 and the loss: 0.5178504586219788\n",
      "Epoch number: 451 and the loss: 0.5164597630500793\n",
      "Epoch number: 461 and the loss: 0.5211407542228699\n",
      "Epoch number: 471 and the loss: 0.5190293192863464\n",
      "Epoch number: 481 and the loss: 0.5161280632019043\n",
      "Epoch number: 491 and the loss: 0.5156705975532532\n",
      "Epoch number: 501 and the loss: 0.5153055191040039\n",
      "Epoch number: 511 and the loss: 0.5196228623390198\n",
      "Epoch number: 521 and the loss: 0.5169117450714111\n",
      "Epoch number: 531 and the loss: 0.5150470733642578\n",
      "Epoch number: 541 and the loss: 0.5144888758659363\n",
      "Epoch number: 551 and the loss: 0.5142431855201721\n",
      "Epoch number: 561 and the loss: 0.5163128972053528\n",
      "Epoch number: 571 and the loss: 0.5156162977218628\n",
      "Epoch number: 581 and the loss: 0.5167715549468994\n",
      "Epoch number: 591 and the loss: 0.5146209597587585\n",
      "Epoch number: 601 and the loss: 0.5139331221580505\n",
      "Epoch number: 611 and the loss: 0.5147527456283569\n",
      "Epoch number: 621 and the loss: 0.5149415731430054\n",
      "Epoch number: 631 and the loss: 0.5162039399147034\n",
      "Epoch number: 641 and the loss: 0.5140596628189087\n",
      "Epoch number: 651 and the loss: 0.5135514140129089\n",
      "Epoch number: 661 and the loss: 0.513079047203064\n",
      "Epoch number: 671 and the loss: 0.512224018573761\n",
      "Epoch number: 681 and the loss: 0.5139999389648438\n",
      "Epoch number: 691 and the loss: 0.5132774114608765\n",
      "Epoch number: 701 and the loss: 0.5120059847831726\n",
      "Epoch number: 711 and the loss: 0.5114647746086121\n",
      "Epoch number: 721 and the loss: 0.5110394954681396\n",
      "Epoch number: 731 and the loss: 0.5109288096427917\n",
      "Epoch number: 741 and the loss: 0.5185254216194153\n",
      "Epoch number: 751 and the loss: 0.5121859908103943\n",
      "Epoch number: 761 and the loss: 0.5116051435470581\n",
      "Epoch number: 771 and the loss: 0.5104056000709534\n",
      "Epoch number: 781 and the loss: 0.5102575421333313\n",
      "Epoch number: 791 and the loss: 0.5166489481925964\n",
      "Epoch number: 801 and the loss: 0.5105974674224854\n",
      "Epoch number: 811 and the loss: 0.5100389122962952\n",
      "Epoch number: 821 and the loss: 0.5092241764068604\n",
      "Epoch number: 831 and the loss: 0.5083472728729248\n",
      "Epoch number: 841 and the loss: 0.5202583074569702\n",
      "Epoch number: 851 and the loss: 0.5115127563476562\n",
      "Epoch number: 861 and the loss: 0.5101931095123291\n",
      "Epoch number: 871 and the loss: 0.5083955526351929\n",
      "Epoch number: 881 and the loss: 0.5075944066047668\n",
      "Epoch number: 891 and the loss: 0.5085961818695068\n",
      "Epoch number: 901 and the loss: 0.5077168941497803\n",
      "Epoch number: 911 and the loss: 0.5070589184761047\n",
      "Epoch number: 921 and the loss: 0.508736789226532\n",
      "Epoch number: 931 and the loss: 0.5084576606750488\n",
      "Epoch number: 941 and the loss: 0.5080077052116394\n",
      "Epoch number: 951 and the loss: 0.5058901309967041\n",
      "Epoch number: 961 and the loss: 0.5073387026786804\n",
      "Epoch number: 971 and the loss: 0.5063188672065735\n",
      "Epoch number: 981 and the loss: 0.5067833662033081\n",
      "Epoch number: 991 and the loss: 0.5061314702033997\n"
     ]
    }
   ],
   "source": [
    "#trigger the propogation\n",
    "epochs=1000\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i = i+1\n",
    "    y_pred = model.forward(X_train_t)\n",
    "    loss=loss_function(y_pred, y_train_t)\n",
    "    final_losses.append(loss.item())\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss: {}\".format(i, loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a66d2187-49df-4ec1-a2b7-78c50e5b12b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEMCAYAAADqG+D0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsg0lEQVR4nO3deXhc1WH38e+dGe2SbVmWF3mT1+MN29js2CQEnKQOtG4SIE6CUwhpSdLkDc3SvmkLNAkpTcPbNIkJFAIFEpwEQlkaA4GE1UDAYGNs7ONFXiXLkiXZkqxtNDPvH/dKHkljaWYsjWTN7/M8PB6de+/oHNnoN2e55zqRSAQREZFE+Qa7AiIicmZSgIiISFIUICIikhQFiIiIJEUBIiIiSQkMdgVSJAs4FzgMhAa5LiIiZwo/MAF4C2jtfjBdAuRc4JXBroSIyBlqOfBq98J0CZDDAHV1JwiHE7/vpagon5qaxn6v1FCmNqcHtTk9JNtmn8+hsDAPvN+h3aVLgIQAwuFIUgHScW26UZvTg9qcHk6zzTGH/jWJLiIiSUlZD8QYMxt4ACgCaoA11tpd3c4ZC9wPTAYygT8CX7XWthtj/MCPgY8CEeB2a+29qaq/iIh0lcoeyF3AWmvtbGAtcHeMc74NbLfWLgTOApYCH/eOfQaYCcwCLgRuNcaUDnSlRUQktpQEiNezWAKs84rWAUuMMcXdTo0ABcYYH+7S20yg3Dt2DXCPtTZsra0GHgeuGui6i4hIbKkawpoMlFtrQwDW2pAxpsIrr44677vAb3Fn/POAn1prN3jHpgD7o8494F0ft6Ki/ORqDxQXFyR97ZlKbU4PanN6GIg2D7VVWFcBW4DLgALgaWPMJ621j/bHm9fUNCa1EqG4uIDq6ob+qMIZQ21OD2pzeki2zT6f0+sH71TNgRwEJnoT4Xh/lnjl0b4C/NIbpjoOPAFc6h07AEyNOndKjOv73bHGVq78+hNs2VMz0N9KROSMkpIAsdZWAZuB1V7RamCTN5cRbS/uKiuMMZnA5cBW79gjwBeMMT5v7mQV7nDXgNpX6ab2H985NNDfSkTkjJLKVVg3Al8xxuzE7WncCGCMWW+MOcc752vAcmPMe7iBsxO4xzv2EFAG7ALeAL5jrS0b6Er7HAdIzxuPRER6k7I5EGvtDuD8GOUro17vAVac4voQ8MUBq+Ap+H1ugIQUICIiXehO9D74vADRs+NFRLpSgPTByw/1QEREulGA9MHvc39EmgMREelKAdIHn+ZARERiUoD0wVuEpR6IiEg3CpA4hTSJLiLShQKkD2EvONQDERHpSgHSh46Oh/JDRKQrBUhfOgIkHB7ceoiIDDEKkD5oCEtEJDYFSJy0jFdEpCsFSB86tjBRfoiIdKUA6YNW74qIxKYA6YM2URQRiU0B0oeOtVfOoNZCRGToUYD0RR0QEZGYFCB90BCWiEhsCpA+KD5ERGJTgPShsweiSRARkS4UIH3QCJaISGwKkD4oQEREYlOA9KFjCEsjWCIiXSlA+qAOiIhIbAqQPmgZr4hIbAqQPig/RERiC6TqGxljZgMPAEVADbDGWrur2zkPAgujihYCq6y1TxpjbgW+BFR4xzZYa7880PVWfoiIxJayAAHuAtZaa39hjPkscDfwoegTrLVrOl4bYxYBfwSejTrlQWvtN1JR2Q4awhIRiS0lQ1jGmLHAEmCdV7QOWGKMKe7lss8Dv7TWtg50/XrTeR+ho3VYIiLRUtUDmQyUW2tDANbakDGmwiuv7n6yMSYT+DRwebdDnzLGfBioBG6x1r6eSCWKivITrnh+wXEAfD6H4uKChK8/k6Vbe0FtThdqc/9I5RBWIlYBB6y1m6PK7gJus9YGjTErgCeMMXOttTXxvmlNTWPCzzavr28G3GeiV1c3JHTtmay4uCCt2gtqc7pQm+Pn8zm9fvBO1Sqsg8BEY4wfwPuzxCuP5XrgvugCa22ltTbovX7Ou3bBgNXYozkQEZHYUhIg1toqYDOw2itaDWyy1sYavpoELAce7lY+Mer1YqAUsANS4SjKDxGR2FI5hHUj8IAx5magDlgDYIxZD9xsrd3onfc54ClrbW23679vjFkKhIA24FprbeVAV1oBIiISW8oCxFq7Azg/RvnKbl/fdorrPzdAVetVRHeCiIjEpDvR+3ByGe/g1kNEZKhRgPRBk+giIrEpQPqg+BARiU0B0gc90VZEJDYFSF80hCUiEpMCpA8J3rguIpI2FCAiIpIUBUgfwhrCEhGJSQHSF+WHiEhMCpA+nLwPROuwRESiKUD6ENad6CIiMSlAREQkKQqQPuTluPtN+nzqgoiIRFOA9OGiBeOZP70IvwJERKQLBUgf/D4fhQVZg10NEZEhRwESB8dxdEe6iEg3CpA4OKA9sUREulGAxMFxHN1PKCLSjQIkDo6jB0uJiHSnAImHoxEsEZHuFCBx8Ok2dBGRHhQgcdIQlohIVwqQODiONuUVEelOARIHB0dzICIi3QRS9Y2MMbOBB4AioAZYY63d1e2cB4GFUUULgVXW2ieNMX7gx8BHcTsEt1tr701F3TUFIiLSUyp7IHcBa621s4G1wN3dT7DWrrHWLrbWLgY+B9QBz3qHPwPMBGYBFwK3GmNKU1Bv7050dUFERKKlJECMMWOBJcA6r2gdsMQYU9zLZZ8HfmmtbfW+vga4x1obttZWA48DVw1QlbtwHDQJIiLSTap6IJOBcmttCMD7s8Ir78EYkwl8GrgvqngKsD/q6wOnur6/6U50EZGeUjYHkqBVwAFr7eb+fNOiovykrnNweyHFxQX9WZ0hL93aC2pzulCb+0eqAuQgMNEY47fWhrwJ8RKvPJbr6dr7ALfHMRV4y/u6e4+kTzU1jYST2VbXgVAoQnV1Q+LXnqGKiwvSqr2gNqcLtTl+Pp/T6wfvlAxhWWurgM3Aaq9oNbDJm8vowhgzCVgOPNzt0CPAF4wxPm/uZBXw24GqczTdiS4i0lMqV2HdCHzFGLMT+Ir3NcaY9caYc6LO+xzwlLW2ttv1DwFlwC7gDeA71tqyga+2O4SlO9FFRLpK2RyItXYHcH6M8pXdvr7tFNeHgC8OTO36oM0URUR60J3ocfBpFZaISA8KkHjoeSAiIj0oQOLgoB6IiEh3CpA46E50EZGeFCBxcBxHQ1giIt0oQOLgcyCZ+w9FRIYzBUgcfD71QEREulOAxMEdwhrsWoiIDC0KkDg4WsYrItKDAiQOHTcSKkRERE5SgMTB8TZTVHyIiJykAImDz9uMVz0QEZGTFCBx6OyBKD9ERDopQOLgqAciItKDAiQOHQ+UCocHuSIiIkOIAiQOPm8SJKweiIhIJwVIHDQHIiLSkwIkDp2rsLSQV0SkkwIkDuqBiIj0FPcz0Y0xlwL7rLV7jTETgNuBEPBta23lQFVwKOjogWgORETkpER6IHfiBgbAHUAG7s3Z/9XflRpqHJ96ICIi3cXdAwEmWmsPGGMCwEeAqUAbUDEgNRtCTg5hKUFERDok0gOpN8aMAz4AvG+tbfTKM/q/WkPLya1MBrceIiJDSSI9kJ8AbwGZwNe8souBHf1cpyHH6byRUAkiItIh7h6ItfbfgMuBi621v/KKy4EbBqJiQ4lPQ1giIj0k0gPBWruz47W3KitkrX05nmuNMbOBB4AioAZYY63dFeO8q4F/BhzcSfrLrbVHjDG3Al/i5JzLBmvtlxOpf7J8XsxqJxMRkZPi7oEYY14yxlzsvf574FfAOmPMt+N8i7uAtdba2cBa4O4Y3+Mc4FZghbV2AbAMOB51yoPW2sXefykJD9AkuohILIlMoi8A3vBefwH4IHABcGNfFxpjxgJLgHVe0TpgiTGmuNupNwE/7LivxFp73FrbkkAdB4RuJBQR6SmRISwfEDHGzAAca+12AGNMYRzXTgbKrbUhAGttyBhT4ZVXR503D9hrjHkZyAceA26z1nb86v6UMebDQCVwi7X29QTqn7SOVVhtwVDvJ4qIpJFEAuRV4KfABOB/ALwwOdrP9VkIrMBd7fUMcAB4EHcI7DZrbdAYswJ4whgz11pbE++bFxXlJ1WpHeX1ANx6/1s8dcdfJPUeZ6Li4oLBrkLKqc3pQW3uH4kEyF8BX8ftMfy7VzYH+M84rj0ITDTG+L3ehx8o8cqj7Qcetda2Aq3GmCeA83DnPjq3S7HWPmeMOYg7rPZSvA2oqWlMailuxyosgOrqhoSvPxMVFxekTVs7qM3pQW2On8/n9PrBO+4A8T7pf7tb2e/ivLbKGLMZWA38wvtzk7W2utupDwMrjTEPeXW7DHgUwBgz0Vpb7r1eDJQCNt76n46o/CAciXQJFBGRdJXIZooZwD8B1+L2HiqAh3CHldrieIsbgQeMMTcDdcAa733XAzdbazfiruw6B3gfd9Xss8DPveu/b4xZirsfVxtwbao2cXSiAqOlNURudkKrn0VEhqVEfhP+AHc46UbcoaapuPdrjMBdPdUra+0O4PwY5SujXoeBv/P+637e5xKoa7/y+04GSFNrUAEiIkJiAXIVsChq0toaY94B3iWOADmTRY9YNbdqJZaICCR2H8ipBv6H/YRA9BBWe0j3o4uIQGI9kEeAp4wx/4K7tHYq7pzIbwaiYkNJ9KR5sF0BIiICiQXIt3ADYy3uJHo57qR31gDUa8hSD0RExJXIMt424GbvPwCMMdnACdxwGbaa29o7XytARERcicyBxBIhDeZATjQHO18H27UhlogInH6AgBsiw1p0gKgHIiLi6nMIyxjzoV4OZ/ZjXYasFedNYf2GvVTWNilAREQ88cyB/LyP4wf6oyJDWX5uJt/41GK+cedrBBUgIiJAHAFirZ2WiooMdYGAO9rXrmW8IiJA/8yBpIUMvxcgoWE/5SMiEhcFSJwCnQGiHoiICChA4hbwu6uVFSAiIi4FSJwcxyHgdzSJLiLiUYAkIOD30a4bCUVEAAVIQgJ+n4awREQ8CpAEZAR8GsISEfEoQBIQ8DvqgYiIeBQgCXDnQBQgIiKgAElIht+nGwlFRDwKkAQENAciItJJAZIADWGJiJykAElAhibRRUQ6KUASkJ0ZoLktNNjVEBEZEhQgCcjNDnCiJdj3iSIiaSCeB0r1C2PMbOABoAioAdZYa3fFOO9q4J9xn7UeAS631h4xxviBHwMf9cpvt9bem6r6A+RlZ9DU0p7KbykiMmSlsgdyF7DWWjsbWAvc3f0EY8w5wK3ACmvtAmAZcNw7/BlgJjALuBC41RhTOvDVPik3O0CwPUywXcNYIiIpCRBjzFhgCbDOK1oHLDHGFHc79Sbgh9baSgBr7XFrbYt37BrgHmtt2FpbDTwOXDXglY+Sl+122E6oFyIikrIhrMlAubU2BGCtDRljKrzy6qjz5gF7jTEvA/nAY8Bt1toIMAXYH3XuAe/6lMnNzgDcABmVn5XKby0iMuSkbA4kTgFgIbACyASewQ2KB/vjzYuK8pO+tri4gJJxzQBkZmdQXFzQH1Ua0tKhjd2pzelBbe4fqQqQg8BEY4zf6334gRKvPNp+4FFrbSvQaox5AjgPN0AOAFOBt7xzu/dI+lRT00g4nPhWJMXFBVRXNxBsdVdglVfWU5yfmfD7nEk62pxO1Ob0oDbHz+dzev3gnZI5EGttFbAZWO0VrQY2eXMZ0R4GPmyMcYwxGcBlwLvesUeALxhjfN7cySrgtwNd92gdcyBNWsorIpLSVVg3Al8xxuwEvuJ9jTFmvbf6CuBXQBXwPm7gbAN+7h17CCgDdgFvAN+x1palrPa4q7BAk+giIpDCORBr7Q7g/BjlK6Neh4G/8/7rfl4I+OJA1rEvuZ09EAWIiIjuRE+A3+cjO9Ovu9FFRFCAJCwvO6AeiIgICpCE5WVn0NisHoiIiAIkQcWjcqg+1jzY1RARGXQKkASNHZ1DVV0zkYgebSsi6U0BkqC87AxC4QhBPZlQRNKcAiRBmQH3R9amABGRNKcASVBmhh+AtqC2dBeR9KYASVBHD6RVASIiaU4BkqCTPRANYYlIelOAJCgzo2MORD0QEUlvCpAEZQa8Hogm0UUkzSlAEpTlDWG1tqkHIiLpTQGSoBztyCsiAihAEtbxUKn3ymoGuSYiIoNLAZKgnCw3QN7aUcWWPUcHuTYiIoNHAZIgn+N0vj7W2DaINRERGVwKkNMQHSYiIulGAZKEr1+zGICmVk2ki0j6UoAkYW5pIY4DDU0awhKR9KUASYLPcZg8Np895ccHuyoiIoNGAZKkycX5ejKhiKQ1BUiSCnIzaWjSs9FFJH0pQJKUmeGjrT3M5l26F0RE0pMCJEk+n7uE97GXywa5JiIigyOQqm9kjJkNPAAUATXAGmvtrm7n3Ap8CajwijZYa7/c17HB8JHzpvD4K3uZWJw3WFUQERlUKQsQ4C5grbX2F8aYzwJ3Ax+Kcd6D1tpvnOI9ejuWUlkZfhbOKGL7vlraQ2ECfnXmRCS9pOS3njFmLLAEWOcVrQOWGGOKU/H9B8rZs8ZQ3xSkrqF1sKsiIpJyqfrYPBkot9aGALw/K7zy7j5ljNlijPm9MebCBI6lXNHIbACefHXvINdERCT1UjmEFY+7gNustUFjzArgCWPMXGttTR/H4lJUlJ90xYqLC3qUGW8vrA1bK1m5fDoLZ57RHaoeYrV5uFOb04Pa3D9SFSAHgYnGGL+1NmSM8QMlXnkna21l1OvnjDEHgQXAS70di7cSNTWNhMORhCtfXFxAdXVDj/IM4OIF49mwtZL3bBUTvB7JcHCqNg9nanN6UJvj5/M5vX7wTskQlrW2CtgMrPaKVgObrLXV0ecZYyZGvV4MlAK2r2OD6fqPzSU/J4PdFfWDXRURkZRK5RDWjcADxpibgTpgDYAxZj1ws7V2I/B9Y8xSIAS0AddG9Tx6OzZoHMfhnDljeXFTOc2t7Z0PnBIRGe5S9tvOWrsDOD9G+cqo15/r5fpTHhtssyaO5MVN5dz/9A6+tGrBYFdHRCQldPNCPzh/3jhG5GXy7u6jNOsZISKSJhQg/cDnc/jKJ84i2B7mvvXbB7s6IiIpoQDpJ9MnjGBEXiZv22qOapt3EUkDCpB+4jgO31x9NgDPv31okGsjIjLwFCD9aOKYPBZMH81zGw+yebe2eReR4U0B0s+++BcLmDw2n7ue2MrewyfvDXlyw15e3XI44ffb8N5hXtpc3p9VFBHpFwqQfpaTFeC6P5uL3+fjew9uZP0b+zlY1cjjr+zlvvXbKUvwhsOf/247DzxjaWnT6i4RGVoUIANg6vgCvv3ZJUwck8ejL+7hBw+/03nsew9u5IVN5bQFQ32+T/S2K8ca2wakriIiyVKADJCJxfn8y/Xn8ZeXTCcj4GPOlFGdxx561nLjHS9x+y/f4bmNB2lqCRKJ9Nyjq/r4ydVc3/6vN9jwXuJDYCKSvIqjJ/S4hl5o340B5DgOV15UypUXlRIOR3j+7UNU1jbx4iZ3TmPnwWPsPHiMdc/vYsrYfCaPzWfRzDHk5WQwa9JIdh863uX9fv677Tzx6l6+9emzGTMyZzCaJJJW/uneP5GTFWDtTZcMdlWGJAVIivh8Dh8+1338yZqPGNqCIfYermfnoeNU1TZRdriet2wVG7a623tlZ/oJRyIUFmR1+QR09HgL3/rZ68yfNprLlkxi7tRCsjL9fX7/dc/vYm9lPd9afbaenjgEhcMR3t9fy/zS0TjeYwJkcNWfcIeNtbvEqSlABklmhh8zpRAzpbCzrLm1nSN1TdQ1tLJtby2twRArzpnMYy+XsWVP18eebNtby7a9tQCMGZnN1PEFjCvMpXhUNuMKc8nLyaCwIIv8nAw27zrKcxvdnfO/vnYDc6cW8skPziA7M0B+TkaX9z1U3cjGHVVc/eE5tLaF8PkcMgIKnIG2Yeth7l+/g+tWzmH5wpLBrs6Q0dDURlVdMzMmjkz59z7WqKGrvihAhpCcrACl40dQOh7OnnXy4VRfu2pR5+vm1nbeK6uhsqaJLWU1nWVby2p5p72a7lMpWRl+WoMhxo3O5UhtEw1NQd7cXsWb26vIz8lgXmkhrW0hzp83jvqmIP/zchmtwRB/2l5FY1MbmRl+rvnQTN621SxbOIHS8QW8trWSmZNGMqNkJC+8c4jX3z/C1R+cSVamn+pjzSyeNQZfL5+i6xpaGZWfOSw/aUciEULhSMK9vMbmIAD2wDEuXjABn294/GzaQ2H2lB/v8kEpEXc9sY3t++v46dcuITc7tb+uWtr6XuiS7hQgZ5icrADnzR0HwJ8vm9blWFNLO40tQapqm2huC1FzvIXa+hYKC7JYvqiETTur2VNxnLqGNmrqW/D7HLbsqSE708+7Xg/HTB7FxOI8/vhOOZkBHyda2rnriW0AvLWjqvN7OQ7MKx3d2Qv64a82EY64vzAWzxxDY3OQEy1BPn35bF5+t4ItZTVc92dz2F1+nOc3HuKypZNYdtYEnn/7IB+7sJS2YIg3t1fxwcUljBmVw86Dx8jJCjB5bD7hcITNu4/SHgpz7pyxXYKnqaWdXYeOMa+0kIxA30N50XYePEZlbROXLOq/T/z3rd/O/soGbrnuXPy++EOkY7jkta2V7K9s4Ls39Ni4OqWq6prYV9nQ4+edqCde3cvvXt/PP167NKleRGVtEwBlh4+zYFpRwtcfPdbMyPzMhP9tgAIkHgqQYSQ3O0BudoCxo2JPsC9fVMLybr8sOz4x7zvcQG52gAlFuYTCEeZOH8PU4lwqjp7AHjzGZUsmsf6N/TQ2B1lxzmSeffMAW8pquHzpJM6aUcSPH93CxOI8JhTl8af3jzAiN4NQOMIdv95MwO+QGfB3BlHA7+MPbx/iD96WL++V1RJsD9HcGuK1rYdZOKOIl991V5x9/JLp7Ck/3hlwr753mFAowtmzxnDB/PHc8evN7K9s4KIF45k7tZCnXtvHhfPHs/KCKfz30+79M5//2DxagyEOVTcyr7QQv89HQ1Mbt//SXV5dfayZg1WNfGvNuYTDkZif/iORCBHotWfV3NrOhvfcOaz7freDBdNHc+H88XH93VXVnVxxV370RFzXDKR7nnqfPRX1jB+dy5RxyT8K9XCNGwD7jzQkFSB+7+/ieBLL2A9VN3Lzz99k1bJpPT5sxSP63qvK2ibGj85N+D2GOyfW8tFhqBTY29+PtB3OEm1zc2s7mRk+HMehrKKeiWPyaG5t583tVSycUURBbgaPvLCHyePyWXbWBP7ryW04jsMF88dx/9M7GFeYw6pl07n7yW20BkNcvGA8R4+3YA8ew+9zuPrSmbxXVsPWvbVkZfppbQvhAH6/w/jReRyqbgQgPyeDxuYguVkBmrzJzxG5GTS1hmgPhZlUnM+Kcyfx0uaKHjd1usNOET512SxmThzJiLxMRuVncaS2iXt/9z7Vx1r45uqzKSlyg7W2oZXS8QUU5GYCsGlnNT957L0u71mQm8E3V5/NpOJTPxYU4P/e/TpHokLkpqsXMa4wh7GFyf3SCoXD3L9+BzMnjeSDiyee8rxT/T1ff/sfAZhUnM+VF5dy7pyxSdXjjl9vZtveWiaOyeOvVs5hRkliIfLNOzdQU98a988x2qtbDnPf+u1MHVfALded21ke77/tl9+t4L+f3tH59X3/8KGE6j4Q/n3dJmZNGsmq5dMTuq4fHmk7DdjX/bh6INIvop/EONP7pJmTFeCj50/pLL/+Y3M7X/+fqHmdJbOL8fscHMfhX//mAppa2ikZk0drMMS7u48yqTifkjF5LFs4ge3761gwbTQbtlZSUX2CZQsnUDImj/vXbyczw8+nL5/Fs28e4K0dVVxz7kyyMvw88sJuLpw5hmklI/jf1/Zx//od5GUH+NKqBby0uZxt++o6gwfgF7/fCbgr4eZMKeT9/e4wXVswzE8e3UJGwNfZSyjIzeDqS2eSl5PB/76+jxG5GdQ3BTvb1tAU5Oafv8msSSO56oMzyckOUFKU22VYqLE52CU8AP7jN+8CcNWlMzhvzjgKcjPIzOh9GGbv4XpysgKMH53LjgPHeG1rJa9traSppZ3Zk0cxuiCL9nDklD3U6Pp0OFTdyM8e38r8ry0nNzujl6tiq/R6IOVHT3Dbg28n9Es4EonQ4NWloSnI9x7cyJ03fSDu+aG6hhYAqo41U3Wsuc92d9d9COtUvdNUCYcjbN9fx/b9dQkHyEBRDyQO6oEMHy1t7ZRV1FM6fgS52QFa2tqprG2isCCb7QePM2fSCB57uYwxI7PZXX6c8uoTLJg2mj+/eBo19S3c8evNjC7I4vJzJjMyL5MnNuylvNoNE7/P4QtXzuO1rZVs2VODmTyKipoTNEQFCsDYUTkU5GZQOmEExSOz2XnoOO/srO7Sa+puRG4GHz1/KhedNZ7MgI+sDD+RCJ2/0F55t4L7n96B3+fwr399AU9s2Ns5nBbN5zh8c/ViAgEfU8cVMLoon0efswTbQ1y0YAKFBVls3FHFnY9v7XHt165axOzJI8nOjO9zZ2swxBfveKlL2dTxBfzTmqVxzQ/VNbTy9bUbupStOGcyqy+fFdf3f+CZHby0uaLz647wivff9mMv7+F/X9vf+XXJmDy+N4hzU0ePN/Otn70OJN4bUg9EpB9kZwaYVzq6y9el40cAcOXy6VRXN3D9yrkxry0amc3amy7pssLqrBlFbNlTQ2FBFhOKcsnLzuDsWcWEwxGyMv0E28OUVRxnVEEW7+46Smt7mF2HjlFX38qrWw7TGgzh9zlcsqiEj104lfVv7GfMyGzeeP9IZzAB1DcF+c0Lu/nNC7sByMsOcKKlncKCLEbmZbKvsoGA36E9FOH2h9+htr6VZWdN4I33K2kPRfD7HEbmZ3KiuZ1/e3gTAMWjssFxqPZ6P8/86QBXXTqTN7ZVkp3p7/EJ/EePvEtGwMelZ0/k4rMm4AAlxXn4HIeGpjb2H2lgfGEuY7xP+h29j2j7Kxv47gMbueGKeX0OR1XV9bz+uY0HOXfu2M5ebm+O1Ha9vrm1vUtPuS/dtw+qOHqCA0caTmtO6HQcPdbS+bo9FB4S93OpBxKH4fppvDdq88ALRyKcaA6Sl5MRc3K+ubWdtvYwwWAIx3Goqmtid0U9LW3t1De2UTgim72H62lqCTJ/WhEfOW8yb2w7wq/+sIulppgbrpjH0eMt5GUHaG0LUZCXyb7D9fzxnXLGj87lta2VjBqRxceXT2dUfiZ3P7mNA0fcuaRrPjQTx3H449uHqOrlAWml4wsYlZ/Fe2U1hLz/tz563hQuXjiBDe8d5pk/HaBkTB4VMRYGmMmjuGRxCTNKRlCQm0lbe5iReZmdx1/cXM6Dz9iY33fp7GJmTBzJ8kUTyIsxtBaJRLjppxs6V7eBOz+2aGYRn/rIXPICfQ9F/eiRd3vcfwXwn19d1jnvlUqvbKng/vXunMyPvrKMEXnx12GgeiAKkDjol2l6GC5tTmSsPrrNoXCYbXvryMsJdJnsrmtoxXFO3m+Uleln695aCvOzeGvHEcLhCBcuGM+C6UW8+f4RXol6bMHS2cVc/7G57KtsoLUtxEZbxWtbuw6t+X0OAb+PtmCIs2YUsWR2MaPys/jd6/uoOtbcuQKraEQ2NfUtdLd45hiWL5pAQW4mk4rzyM4McOBIA7fe/1bMNvscuOGKeSyeNYbMDP8pV9b94z1vdK4i6+6mqxdx1vS+lxW3toW4/+ntLJ41hgvm9VyRd6IliIMT1z0u//NyGU+9tg9we4/f/uxSRuZn9XkdKEBOVykKkISozemhP9ociUS6LAqorG1iT/lxfD6Hc8zYHjsZhCMRDlU1EvD72F1+nN3lx/E5DjlZft54/0iXJbufWTGbeaWF1NS3sGBaEa3BENXHmikakc2rWw7zypbDVBw9Qdj7PRbwOxTkZnKiOYjjOFy3ck7n8vFYpk0YwbzSQk40B1kyu5h500bjcxzagiG+/B8vs3xRCZU1J3Ach/KjJ7r0aAA+++HZXDBvHNlZgZhB9MiLu3n6jQM4wNc/tZi7n9zG/NLR3HDlPGrrW7jtobfJDPi49brzeOhZS15OBqsvnxXzve55ahuvbzvS+XV+TgYfPLuEj18yo/e/IBQgp6sUBUhC1Ob0MNTaHI5EOHqsmfoTQQpyMxgXx70Xza3tlB2up60txO7y4+6iBQcuPXsi0ya481vtoTDvldXgcxz2HG7glc3lNLe2E45EaA9FOndsyMr0M2ZkNsH2MFV1zXxz9dnMnXryLvo/vH2IXz63s0cdxo3OZe7UQopGZDFxTD4RIpRV1PP0GwcYmZ/ZY0ff61bO4Zk/Hejs4UwZl985fPjVTy7EAbbvr+OcOSfne257aCM1x1t6zM1csmgClyyayPSSEaf8GSlATk8pCpCEqM3pIV3bfKSqHp/j0NgcpC0YYkReJhttFXsO1VPX2Ep7KMxZ04u4bOmkmO9xoiXIjv117Dp0nOpjzZRV1NPU2k6wPdzlvCWzi7lu5Rz+/mev09Tazlc/sZBfPmepqW8l4He46apF/Odvt9AWDDN/2ugu28c7QAS4bOkk5k8bzU9/+x4rzp3Es28ejFmnhTOKuGD+OPKyM3jbVnHFRaWMGZnD3sP1LJk/gbraxG9QVYC4SlGAJERtTg9qc//o2KmgpTXE4ZoT+HwOxaNyOjcr3XvYDZj5paPZvPsoz711kD+7YAoLphXx/MaDvLS5gq9+ciFby2p46Pc7ufTsiXziA9O549eb2XvYrWtmwMd3Pn8etfWtvG2rOdES5P39dT2G1ToUFmQxqTif98pquOWGC5g6JvGbUodMgBhjZgMPAEVADbDGWrur2zm3Al8COhZvb7DWftk75gd+DHwUN5hvt9beG+e3L0UBkhC1OT2ozUNPXUMrhQXu5Hh7KMyb24/QHoowZ8qoHjsTBNvdFXqvbDlMXnaAlzZXkJXh57Klk7jz8a00t7Zz7pyx/OP151M7AD2QVN4Hchew1lr7C2PMZ4G7gVh3wzxorf1GjPLPADOBWbghtMkY87y1dt9AVVhEJNU6wgPc7XUuWjDhlOd2bBJ56dnudjUdG60C/PBLF9HU0k7hiCz8A3TPSEruRDHGjAWWAOu8onXAEmNM8amv6uEa4B5rbdhaWw08DlzVrxUVERkmcrICFI3M7nUD0NOVqlsZJwPl1toQgPdnhVfe3aeMMVuMMb83xlwYVT4F2B/19YFTXC8iIikw1LYyuQu4zVobNMasAJ4wxsy11va8HTQJ3lheUoqLB2f7gsGkNqcHtTk9DESbUxUgB4GJxhi/tTbkTYiXeOWdrLWVUa+fM8YcBBYAL+H2OKYCHbeXdu+R9EmT6PFTm9OD2pwe+uE+kNjHT6dS8bLWVgGbgdVe0WpgkzeX0ckYMzHq9WLc1VMdm+E8AnzBGOPz5k5WAb8dyHqLiMippXII60bgAWPMzUAdsAbAGLMeuNlauxH4vjFmKRAC2oBro3olDwHnAx1Lf79jrS1LYf1FRCRKygLEWrsDNwC6l6+Mev25Xq4PAV8cmNqJiEiihtok+kDxA6f1NLHBfBLZYFGb04PanB6SaXPUNTEfh5kuW5ksA14Z7EqIiJyhlgOvdi9MlwDJAs4FDuPOr4iISN/8wATc1a+t3Q+mS4CIiEg/G/yH6oqIyBlJASIiIklRgIiISFIUICIikhQFiIiIJEUBIiIiSVGAiIhIUtJlK5OkxfMs9zONMaYId3PKGbg3B+0G/sZaW91be4fDz8IYcwtwK3CWtXbrcG6vMSYb+A/gcqAFeN1a+9fDvM1XAN8FHNwPyLdaax8bTm02xvwQ+ATubuVnWWu3euVJtfF02q8eSN86nuU+G1iL+yz3M10E+IG11lhrFwJ7gNu9Y72194z+WRhjlgAX4D5bpsOwbS/wA9zgmG2tPQv4Z698WLbZGOPgfjC61lq7GPgs7g7gPoZXmx8HLqHn85CSbWPS7ded6L3wnuW+EyiKehBWDTCr+7NMzmTGmE/g7nT8aU7RXtxPdGfsz8IYkwW8iNvGF4ArgCqGb3vzgUPAJGttY1T5Kf9Nc+a32QGOAn9urd1gjLkEuBd3L7xh12ZjzD7gCq8nndTfa2/H4mm/eiC9S+RZ7mck79PZF4En6b29Z/rP4jvAL6y1e6PKhnN7Z+D+IrjFGLPRGPOiMWYZw7jN1toIcDXuo7D3435S/xzDuM1Rkm3jabVfASI/ARqBnw52RQaKMeZC3M007xzsuqRQAJiO++TPc4C/Bx4DTv180jOcMSYA/F/gL6y1U4ErgV8zjNs82BQgvet8ljvAqZ7lfqbyJuNmAddYa8P03t4z+WfxAWAOsNfr9k8CnsX9lD4c2wvu+Hg7sA7AWvsn3OGdZoZvmxcDJdbaDQDenydw54GGa5s7JPv/7mm1XwHSi3if5X4mMsbcBiwFVllrW6H39p7JPwtr7e3W2hJrbam1thR3buAj1trfMAzbC2CtPYo717MCOlfadIyTb2YYthlvzscYYwCMMXOB8biPwd7M8GwzkPz/u6fbfk2i98EYMwd3iVsh3rPcrbV2cGt1eowx84GtuL9Mmr3ivdbav+ytvcPlZ9Ft8nHYttcYMx24D3d5ZhD4R2vt08O8zZ8B/gEIe0W3WGsfH05tNsb8GPg4bjgeBWqstfOTbePptF8BIiIiSdEQloiIJEUBIiIiSVGAiIhIUhQgIiKSFAWIiIgkRQEicgYxxkSMMTMHux4ioO3cRU6Ld0/JOCAUVfzf1tq/HZwaiaSOAkTk9F1prX1+sCshkmoKEJEBYIz5K+ALwDvAGuAw8GVr7R+84yW4z2FYBtQC/2atvcc75sfd/PDznNx+ZJW1tmN/osuNMU8DY4CHgb/1dqIVSSnNgYgMnPOBMtxf9LcAjxljRnvH1uHu3VQCfBL4vjHmMu/Y3+HuSbQSGAFcDzRFve8VuLsLL8LdvvwjA9sMkdjUAxE5fY8bY9qjvv4m7t5TVcCPvN7Br40xXwc+Zox5EbfncYW1tgXYbIy5F7gW+ANwA/CtqP2I3u32/W631h4DjhljXsDdhfaZAWmZSC8UICKnb1X3ORBvCKu829DSftweRwlQa61t6HbsHO/1ZNzHDJ9KZdTrJvS8CxkkGsISGTgTvcesdpiC+7S3CmC0Maag27Fy7/VB3GeViAxp6oGIDJyxwFeNMXcCq4C5wHprbY0x5jXgX40x3wBm406Yf9a77l7gu8aY94HdwFm4vZmaVDdApDcKEJHT95QxJvo+kOeAJ4A/4T7x8ShwBPhkVAisxl2FVYH7DIZbrLXPecf+H5AF/B53An4H8JcD3QiRROl5ICIDwJsDucFau2yw6yIyUDQHIiIiSVGAiIhIUjSEJSIiSVEPREREkqIAERGRpChAREQkKQoQERFJigJERESSogAREZGk/H9RVU1cb5ih9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss function\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs), final_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb607bf-465d-4486-9f6f-3cd83e2ee7ba",
   "metadata": {},
   "source": [
    "## 5. Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "548a7ce4-a5e8-4302-9ad3-d0ba5a81f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create prediction with with X_test_t\n",
    "#Don't need gradient for this\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "  for i, value in enumerate(X_test_t):\n",
    "    y_pred = model(value)\n",
    "    test_predictions.append(y_pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0fb4b8a9-19ab-48f4-98fd-16045e7fd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipping actual value and predictions\n",
    "#since we need two arrays, we convert the tensor to a numpy array\n",
    "zipped_values = zip(y_test_t.numpy(), test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fb3df20-7af7-41ff-a508-678b3df1ea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 0), (0, 0), (1, 1), (0, 0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the first 5 predictions\n",
    "list(zipped_values)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93342bf0-7bb2-4f49-9705-1f2fe26beeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7758, 3003],\n",
       "       [2707, 7924]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "m = confusion_matrix(y_test_t.numpy(),test_predictions)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e14d83d0-c303-4e1c-9103-41ac0364d278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7330777860882572"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test_t.numpy(), test_predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4964d4c-78fc-4cc1-97d2-1cbd3ae77ff3",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05141535-3cc6-4500-9a90-0ae5acb80707",
   "metadata": {},
   "source": [
    "With the use of PyTorch, I basically did not see any improvement. Actually, the Logistic Regression model gave a slightly better performance. However, there are things that I can play around with to see if the accuracy and other assessment metrics can be improved.\n",
    "I could make the network be a little deeper than just using 2 hidden layers. This also means that I would increase the number epochs. This might take some while to run and because this notebook runs on my laptop, I will leave that for future exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
